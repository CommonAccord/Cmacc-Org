
Ti=PRIVACY TERMS

Data_Subject.Ti={Def.Data_Subject.Target}

Data_Subject.sec=A {_Data_Subject} may refer to an individual, organization, product, event, or any other person, place, or thing about which data is collected.  

Data_Subject.Note=This definition is scoped more broadly than traditional privacy policies or {_Data_Subject} definitions.

Data_Subject.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Dataset.Ti={Def.Dataset.Target}

Dataset.sec=A {_Dataset} is information that contains attributes about or relations between one or more {_Data_Subjects}.

Dataset.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Personally_Identifiable_Information.Ti={Def.Personally_Identifiable_Information.Target}

Personally_Identifiable_Information.sec={_Personally_Identifiable_Information} is any and all information that could be interpreted as relating to individuals under a statute, regulation, or ruling related to the Organization.  Privacy frameworks vary across jurisdictions and industries in their classification of personally identifiable information, and this definition is meant to capture information under all such relevant frameworks.

Personally_Identifiable_Information.Synomyms=Personally Identifying Information, PII, Personal Information, Personal Data

Personally_Identifiable_Information.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Pseudo-anonymization.Ti={Def.Pseudo-anonymization.Target}

Pseudo-anonymization.sec={_Pseudo-anonymization} is the process of transforming data to increase the cost or decrease the probability of inferring selected information about a {_Data_Subject}.  The term anonymization is used colloquially to describe pseudo-anonymization which results in either a cost exceeding reasonable feasibility or a probability approaching zero.

Pseudo-anonymization.Synonyms=pseudo-anonymisation 

Pseudo-anonymization.SeeAlso=anonymization

Pseudo-anonymization.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Anonymization.Ti={Def.Anonymization.Target}

Anonymization.sec={_Anonymization} is a term used to describe a pseudo-anonymization process which results in either a cost exceeding reasonable feasibility or a probability approaching zero of inferring selected information about a {_Data_Subject}.  

Anonymization.Note={_Anonymization} is context-dependent; Personnel should consider the budget and resources of potential threat actors and monitor trends in computation, storage, and data breach that might otherwise reduce the cost of de-anonymizing a {_Dataset} that was previously deemed to be Anonymized.

Anonymization.Synonyms=anonymisation

Anonymization.SeeAlso=pseudo-anonymization

Anonymization.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Re-identification.Ti={Def.Re-identification.Target}

Re-identification.sec={_Re-identification} is the process of inferring {_Data_Subject} identity from data that has been previously omitted or pseudo-anonymized.

Re-identification.Synonyms=de-anonymization, de-anonymisation, identity disclosure

Re-identification.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

K-Anonymity.Ti={Def.k-anonymity.Target}

K-Anonymity.sec={_k-anonymity} is a measure of the size of the smallest group of {_Data_Subjects} indistinguishable from each other by their attributes within a pseudo-anonymized dataset.  If a dataset has k=1-anonymity, then there is at least one {_Data_Subject} with unique attributes that is at increased risk of re-identification.  In general, datasets with larger {_k-anonymity} values have lower probabilities of re-identification than those with lower value.  However, approaches based on {_k-anonymity} may be vulnerable to targeted attacks that could be avoided through the use of {_l-diversity} or {_t-closeness} metrics.

K-Anonymity.SeeAlso={_l-diversity}, {_t-closeness}

K-Anonymity.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

L-Diversity_and_T-Closeness.Ti={Def.l-diversity.Target} and {Def.t-closeness.Target}

L-Diversity_and_T-Closeness.sec={_l-diversity} and {_t-closeness} are a family of measures of the distribution of sensitive attributes within groups of {_Data_Subjects} in a dataset, such as through the number of distinct values or attribute entropy.  In general, datasets with larger {_l-diversity} or {_t-closeness} values have lower probabilities of re-identification than those with lower values.  Privacy approaches based on {_l-diversity} and {_t-closeness} are generally less susceptible to attack than those based on {_k-anonymity}. {_t-closeness} is a refinement of {_l-diversity} that provides a higher degree of differential privacy.

L-Diversity_and_T-Closeness.SeeAlso={_k-anonymity}

L-Diversity_and_T-Closeness.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Motivated_Intruder.Ti={Def.Motivated_Intruder.Target}

Motivated_Intruder.sec=A hypothetical threat actor whose goal is to re-identify one or more {_Data_Subjects} from a Pseudo-Anonymized {_Dataset}.  This threat actor has access to reasonably-accessible sources of information, such as public records or information leaked via other data breaches.  Typically, this hypothetical threat actor is used to construct estimates of the cost or probability of re-identification for a given {_Data_Subject} or {_Dataset}.

Motivated_Intruder.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]


sec=<ol><li>{Data_Subject.Sec}</li><li>{Dataset.Sec}</li><li>{Personally_Identifiable_Information.Sec}</li><li>{Pseudo-anonymization.Sec}</li><li>{Anonymization.Sec}</li><li>{Re-identification.Sec}</li><li>{K-Anonymity.Sec}</li><li>{L-Diversity_and_T-Closeness.Sec}</li><li>{Motivated_Intruder.Sec}</li></ol>

CodersNote=Deleting the "Example" field.

=[G/Z/Base]
