Ti=FAIRNESS TERMS

Modeling.Ti={Def.Modeling}

Modeling.sec={_Modeling} is any activity that might be described as inferential, causal, predictive, or generative modeling in nature.  The most common activities relate to the creation or management of feature or input data, the preprocessing or engineering of such feature or input data, and clustering, classification, regression, hyperparameter optimization, generation, or simulation using such feature or input data.  The output of a {_Modeling} activity is referred to as a {_Model}.

Modeling.Example=A classification algorithm used to screen resumes for hiring is a {_Model}.  The process of obtaining the data from an HR system, engineering features from this data, and fitting a decision tree to the data is {_Modeling}.

Modeling.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Algorithmic_Bias.Ti={Def.Algorithmic_Bias}

Algorithmic_Bias.sec=A {_Model} can be described as having {_Algorithmic_Bias} when it produces systematically unfair inferences or outcomes.  {_Algorithmic_Bias} can occur in any type of {_Modeling} or {_Model}.

Algorithmic_Bias.SeeAlso={_Training_Data_Bias}, {_Target_Bias}

Algorithmic_Bias.Example=A classification algorithm is used to screen resumes for hiring.  The algorithm systematically rejects older applicants.

Algorithmic_Bias.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Training_Data_Bias.Ti={Def.Training_Data_Bias}

Training_Data_Bias.sec=A {_Model} can be described as having {_Training_Data_Bias} when the features or inputs used in {_Modeling} result in {_Algorithmic_Bias}.  {_Training_Data_Bias} can arise in a number of ways, such as the manner of {_Data_Subject} identification or the inclusion, omission, processing, or annotation of attributes related to the {_Data_Subjects}.

Training_Data_Bias.SeeAlso={_Algorithmic_Bias}, {_Target_Bias}

Training_Data_Bias.Example=A classification algorithm is used to screen resumes for hiring.  The algorithm is trained on a {_Dataset} that does not include any older applicants.

Training_Data_Bias.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Target_Bias.Ti={Def.Target_Bias}

Target_Bias.sec=A {_Model} can be described as having {_Target_Bias} when the targets, labels, or objectives used in {_Modeling} result in {_Algorithmic_Bias}.  There are various ways in which {_Target_Bias} is introduced, such as the framing of the research problem, the manner of {_Data_Subject} identification or sampling, or the inclusion, omission, processing, or annotation of attributes related to the {_Data_Subjects}.

Target_Bias.SeeAlso={_Algorithmic_Bias}, Training Bias

Target_Bias.Example=A classification algorithm is used to screen resumes for hiring.  The target used to fit the classification algorithm is based on whether the applicant will remain at the Organization for at least 10 years.

Target_Bias.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Fairness_Metric.Ti={Def.Fairness_Metric}

Fairness_Metric.sec=A {_Fairness_Metric} is a quantitative measure of algorithmic bias in a {_Model}.  There are a wide range of such metrics, some of which are focused on specific outcomes or units, such as wealth or salary.

Fairness_Metric.SeeAlso={_Statistical_Parity}, {_Predictive_Parity}, {_Theil_Index}

Fairness_Metric.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Statistical_Parity.Ti={Def.Statistical_Parity}

Statistical_Parity.sec={_Statistical_Parity} is a fairness measure based on the difference in a Model’s positive rate based on a protected Attribute.  A {_Model} can be said to exhibit {_Statistical_Parity} if its positive rate is not statistically-significantly different across selected groups.

Statistical_Parity.SeeAlso={_Predictive_Parity}, {_Equal_Opportunity}, {_Theil_Index}

Statistical_Parity.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Predictive_Parity.Ti={Def.Predictive_Parity}

Predictive_Parity.sec={_Statistical_Parity} is a fairness measure based on the difference in a {_Model}’s precision based on a protected Attribute.  A {_Model} can be said to exhibit {_Predictive_Parity} if its precision is not statistically-significantly different across selected groups.

Predictive_Parity.SeeAlso={_Statistical_Parity}, {_Equal_Opportunity}, {_Theil_Index}

Predictive_Parity.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Equal_Opportunity.Ti={Def.Equal_Opportunity}

Equal_Opportunity.sec={_Statistical_Parity} is a fairness measure based on the difference in a {_Model}’s false negative rate based on a protected Attribute.  A {_Model} can be said to exhibit {_Equal_Opportunity} if its false negative rate is not statistically-significantly different across selected groups.

Equal_Opportunity.SeeAlso={_Statistical_Parity}, {_Predictive_Parity}, {_Theil_Index}

Equal_Opportunity.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Theil_Index.Ti={Def.Theil_Index}

Theil_Index.sec=The {_Theil_Index} is an inequality measure based on the degree to which an income or wealth distribution varies from a baseline distribution.  Larger values correspond to more inequality, not more fairness.

Theil_Index.SeeAlso={_Statistical_Parity}, {_Predictive_Parity}, {_Equal_Opportunity}, {_Atkinson_Index}

Theil_Index.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

Atkinson_Index.Ti={Def.Atkinson_Index}

Atkinson_Index.sec=The {_Atkinson_Index} is an inequality measure based on normalizing the Theil index.  Values closer to 1 indicate more inequality, whereas values closer to 0 indicate more equality of income.

Atkinson_Index.SeeAlso={_Statistical_Parity}, {_Predictive_Parity}, {_Equal_Opportunity}, {_Theil_Index}

Atkinson_Index.=[G/responsible-data-use-policy/PrOb/RDSP-Def/Sec/Z/Sec.md]

sec=<ol><li>{Modeling.Sec}</li><li>{Algorithmic_Bias.Sec}</li><li>{Training_Data_Bias.Sec}</li><li>{Target_Bias.Sec}</li><li>{Fairness_Metric.Sec}</li><li>{Statistical_Parity.Sec}</li><li>{Predictive_Parity.Sec}</li><li>{Equal_Opportunity.Sec}</li><li>{Theil_Index.Sec}</li><li>{Atkinson_Index.Sec}</li></ol>

=[G/Z/Base]