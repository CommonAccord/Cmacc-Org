ANNEX IV

Technical documentation referred to in Article 11(1)

The technical documentation referred to in Article 11(1) shall contain at least the following information, as applicable to the relevant {_AI_system}:

1.

A general description of the {_AI_system} including:

(a) its {_intended_purpose}, the name of the {_provider} and the version of the system reflecting its relation to previous versions;

(b) how the {_AI_system} interacts with, or can be used to interact with, hardware or software, including with other {_AI_systems}, that are not part of the {_AI_system} itself, where applicable;

(c) the versions of relevant software or firmware, and any requirements related to version updates;

(d) the description of all the forms in which the {_AI_system} is placed on the market or put into service, such as software packages embedded into hardware, downloads, or APIs;

(e) the description of the hardware on which the {_AI_system} is intended to run;

(f) where the {_AI_system} is a component of products, photographs or illustrations showing external features, the marking and internal layout of those products;

(g) a basic description of the user-interface provided to the {_deployer};

(h) {_instructions_for_use} for the {_deployer}, and a basic description of the user-interface provided to the {_deployer}, where applicable;

2.

A detailed description of the elements of the {_AI_system} and of the process for its development, including:

(a) the methods and steps performed for the development of the {_AI_system}, including, where relevant, recourse to pre-trained systems or tools provided by third parties and how those were used, integrated or modified by the {_provider};

(b) the design specifications of the system, namely the general logic of the {_AI_system} and of the algorithms; the key design choices including the rationale and assumptions made, including with regard to persons or groups of persons in respect of who, the system is intended to be used; the main classification choices; what the system is designed to optimise for, and the relevance of the different parameters; the description of the expected output and output quality of the system; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Chapter III, Section 2;

(c) the description of the system architecture explaining how software components build on or feed into each other and integrate into the overall processing; the computational resources used to develop, train, test and validate the {_AI_system};

(d) where relevant, the data requirements in terms of datasheets describing the training methodologies and techniques and the {_training_data} sets used, including a general description of these data sets, information about their provenance, scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection);

(e) assessment of the human oversight measures needed in accordance with Article 14, including an assessment of the technical measures needed to facilitate the interpretation of the outputs of {_AI_systems} by the {_deployers}, in accordance with Article 13(3), point (d);

(f) where applicable, a detailed description of pre-determined changes to the {_AI_system} and its performance, together with all the relevant information related to the technical solutions adopted to ensure continuous compliance of the {_AI_system} with the relevant requirements set out in Chapter III, Section 2;

(g) the validation and testing procedures used, including information about the validation and {_testing_data} used and their main characteristics; metrics used to measure accuracy, robustness and compliance with other relevant requirements set out in Chapter III, Section 2, as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to under point (f);

(h) cybersecurity measures put in place;

3.

Detailed information about the monitoring, functioning and control of the {_AI_system}, in particular with regard to: its capabilities and limitations in performance, including the degrees of accuracy for specific persons or groups of persons on which the system is intended to be used and the overall expected level of accuracy in relation to its {_intended_purpose}; the foreseeable unintended outcomes and sources of {_risks} to health and safety, fundamental rights and discrimination in view of the {_intended_purpose} of the {_AI_system}; the human oversight measures needed in accordance with Article 14, including the technical measures put in place to facilitate the interpretation of the outputs of {_AI_systems} by the {_deployers}; specifications on {_input_data}, as appropriate;

4.

A description of the appropriateness of the performance metrics for the specific {_AI_system};

5.

A detailed description of the {_risk} management system in accordance with Article 9;

6.

A description of relevant changes made by the {_provider} to the system through its lifecycle;

7.

A list of the {_harmonised_standards} applied in full or in part the references of which have been published in the Official Journal of the European Union; where no such {_harmonised_standards} have been applied, a detailed description of the solutions adopted to meet the requirements set out in Chapter III, Section 2, including a list of other relevant standards and technical specifications applied;

8.

A copy of the EU declaration of conformity referred to in Article 47;

9.

A detailed description of the system in place to evaluate the {_AI_system} performance in the post-market phase in accordance with Article 72, including the post-market monitoring plan referred to in Article 72(3).
